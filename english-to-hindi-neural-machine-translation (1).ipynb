{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":441417,"sourceType":"datasetVersion","datasetId":200079}],"dockerImageVersionId":25160,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimport string\nfrom string import digits\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport re\n\n# Any results you write to the current directory are saved as output.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-13T07:14:16.043839Z","iopub.execute_input":"2024-09-13T07:14:16.044248Z","iopub.status.idle":"2024-09-13T07:14:16.050920Z","shell.execute_reply.started":"2024-09-13T07:14:16.044170Z","shell.execute_reply":"2024-09-13T07:14:16.050164Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"data=pd.read_csv(\"../input/Hindi_English_Truncated_Corpus.csv\",encoding='utf-8')","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2024-09-13T07:14:16.057151Z","iopub.execute_input":"2024-09-13T07:14:16.057418Z","iopub.status.idle":"2024-09-13T07:14:16.749505Z","shell.execute_reply.started":"2024-09-13T07:14:16.057364Z","shell.execute_reply":"2024-09-13T07:14:16.748632Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"data=data[data['source']=='ted']","metadata":{"execution":{"iopub.status.busy":"2024-09-13T07:14:16.751037Z","iopub.execute_input":"2024-09-13T07:14:16.751411Z","iopub.status.idle":"2024-09-13T07:14:16.803728Z","shell.execute_reply.started":"2024-09-13T07:14:16.751347Z","shell.execute_reply":"2024-09-13T07:14:16.803101Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-13T07:14:16.805177Z","iopub.execute_input":"2024-09-13T07:14:16.805429Z","iopub.status.idle":"2024-09-13T07:14:16.832242Z","shell.execute_reply.started":"2024-09-13T07:14:16.805380Z","shell.execute_reply":"2024-09-13T07:14:16.831467Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"   source                        ...                                                             hindi_sentence\n0     ted                        ...                          राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...\n1     ted                        ...                          मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...\n3     ted                        ...                             हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते\n7     ted                        ...                           और हम होते कौन हैं यह कहने भी वाले कि वे गलत हैं\n13    ted                        ...                                                           तो वहाँ न्याय है\n\n[5 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>source</th>\n      <th>english_sentence</th>\n      <th>hindi_sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ted</td>\n      <td>politicians do not have permission to do what ...</td>\n      <td>राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ted</td>\n      <td>I'd like to tell you about one such child,</td>\n      <td>मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ted</td>\n      <td>what we really mean is that they're bad at not...</td>\n      <td>हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>ted</td>\n      <td>And who are we to say, even, that they are wrong</td>\n      <td>और हम होते कौन हैं यह कहने भी वाले कि वे गलत हैं</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>ted</td>\n      <td>So there is some sort of justice</td>\n      <td>तो वहाँ न्याय है</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data.drop_duplicates(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-13T07:14:16.833706Z","iopub.execute_input":"2024-09-13T07:14:16.833975Z","iopub.status.idle":"2024-09-13T07:14:16.930994Z","shell.execute_reply.started":"2024-09-13T07:14:16.833923Z","shell.execute_reply":"2024-09-13T07:14:16.930135Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"* ### Let us pick any 25000 rows from the dataset.","metadata":{}},{"cell_type":"code","source":"data = data.sample(n = 20000 ,random_state = 42)","metadata":{"execution":{"iopub.status.busy":"2024-09-13T07:14:16.932350Z","iopub.execute_input":"2024-09-13T07:14:16.932631Z","iopub.status.idle":"2024-09-13T07:14:16.944768Z","shell.execute_reply.started":"2024-09-13T07:14:16.932576Z","shell.execute_reply":"2024-09-13T07:14:16.943965Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"data['english_sentence']=data['english_sentence'].apply(lambda x: x.lower())\ndata['hindi_sentence']=data['hindi_sentence'].apply(lambda x: x.lower())","metadata":{"execution":{"iopub.status.busy":"2024-09-13T07:14:16.946536Z","iopub.execute_input":"2024-09-13T07:14:16.947012Z","iopub.status.idle":"2024-09-13T07:14:16.990460Z","shell.execute_reply.started":"2024-09-13T07:14:16.946947Z","shell.execute_reply":"2024-09-13T07:14:16.989465Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import string","metadata":{"execution":{"iopub.status.busy":"2024-09-13T07:14:16.991958Z","iopub.execute_input":"2024-09-13T07:14:16.992246Z","iopub.status.idle":"2024-09-13T07:14:16.995625Z","shell.execute_reply.started":"2024-09-13T07:14:16.992200Z","shell.execute_reply":"2024-09-13T07:14:16.994770Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"translator = str.maketrans('', '', string.punctuation)\ndata['english_sentence'] = data['english_sentence'].apply(lambda x: x.translate(translator))\ndata['hindi_sentence'] = data['hindi_sentence'].apply(lambda x: x.translate(translator))","metadata":{"execution":{"iopub.status.busy":"2024-09-13T07:14:16.996981Z","iopub.execute_input":"2024-09-13T07:14:16.997267Z","iopub.status.idle":"2024-09-13T07:14:17.179163Z","shell.execute_reply.started":"2024-09-13T07:14:16.997220Z","shell.execute_reply":"2024-09-13T07:14:17.178241Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"remove_digits = str.maketrans('', '', digits)\ndata['english_sentence']=data['english_sentence'].apply(lambda x: x.translate(remove_digits))\ndata['hindi_sentence']=data['hindi_sentence'].apply(lambda x: x.translate(remove_digits))\n\ndata['hindi_sentence'] = data['hindi_sentence'].apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))\n\ndata['english_sentence']=data['english_sentence'].apply(lambda x: x.strip())\ndata['hindi_sentence']=data['hindi_sentence'].apply(lambda x: x.strip())\ndata['english_sentence']=data['english_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\ndata['hindi_sentence']=data['hindi_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\n","metadata":{"execution":{"iopub.status.busy":"2024-09-13T07:14:17.180675Z","iopub.execute_input":"2024-09-13T07:14:17.180968Z","iopub.status.idle":"2024-09-13T07:14:17.658033Z","shell.execute_reply.started":"2024-09-13T07:14:17.180913Z","shell.execute_reply":"2024-09-13T07:14:17.657200Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Add start and end tokens to target sequences\ndata['hindi_sentence'] = data['hindi_sentence'].apply(lambda x : '$ '+ x + ' %')","metadata":{"execution":{"iopub.status.busy":"2024-09-13T07:14:17.659600Z","iopub.execute_input":"2024-09-13T07:14:17.659880Z","iopub.status.idle":"2024-09-13T07:14:17.679068Z","shell.execute_reply.started":"2024-09-13T07:14:17.659826Z","shell.execute_reply":"2024-09-13T07:14:17.677679Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-13T07:14:17.680432Z","iopub.execute_input":"2024-09-13T07:14:17.680720Z","iopub.status.idle":"2024-09-13T07:14:17.705239Z","shell.execute_reply.started":"2024-09-13T07:14:17.680676Z","shell.execute_reply":"2024-09-13T07:14:17.704176Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"       source                        ...                                                             hindi_sentence\n82040     ted                        ...                          $ हम अभी तक नहीं जानते हैं कि उसके मातापिता कौ...\n85038     ted                        ...                                                      $ कोई कुंजीपटल नहीं %\n58018     ted                        ...                                            $ लेकिन एक कलाकार होने के साथ %\n74470     ted                        ...                                                     $ और यह खास गुब्बारा %\n122330    ted                        ...                          $ और जितना आपको लगता है यह उतना कठिन नहीं हैअप...\n\n[5 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>source</th>\n      <th>english_sentence</th>\n      <th>hindi_sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>82040</th>\n      <td>ted</td>\n      <td>we still dont know who her parents are who she is</td>\n      <td>$ हम अभी तक नहीं जानते हैं कि उसके मातापिता कौ...</td>\n    </tr>\n    <tr>\n      <th>85038</th>\n      <td>ted</td>\n      <td>no keyboard</td>\n      <td>$ कोई कुंजीपटल नहीं %</td>\n    </tr>\n    <tr>\n      <th>58018</th>\n      <td>ted</td>\n      <td>but as far as being a performer</td>\n      <td>$ लेकिन एक कलाकार होने के साथ %</td>\n    </tr>\n    <tr>\n      <th>74470</th>\n      <td>ted</td>\n      <td>and this particular balloon</td>\n      <td>$ और यह खास गुब्बारा %</td>\n    </tr>\n    <tr>\n      <th>122330</th>\n      <td>ted</td>\n      <td>and its not as hard as you think integrate cli...</td>\n      <td>$ और जितना आपको लगता है यह उतना कठिन नहीं हैअप...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"### Get English and Hindi Vocabulary\neng_word_corpus=set()\nfor eng in data['english_sentence']:\n    for word in eng.split():\n        if word not in eng_word_corpus:\n            eng_word_corpus.add(word)\n\nhindi_word_corpus=set()\nfor hin in data['hindi_sentence']:\n    for word in hin.split():\n        if word not in hindi_word_corpus:\n            hindi_word_corpus.add(word)","metadata":{"execution":{"iopub.status.busy":"2024-09-13T07:14:17.706631Z","iopub.execute_input":"2024-09-13T07:14:17.706897Z","iopub.status.idle":"2024-09-13T07:14:17.833740Z","shell.execute_reply.started":"2024-09-13T07:14:17.706851Z","shell.execute_reply":"2024-09-13T07:14:17.833108Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"data['length_eng_sentence']=data['english_sentence'].apply(lambda x:len(x.split(\" \")))\ndata['length_hin_sentence']=data['hindi_sentence'].apply(lambda x:len(x.split(\" \")))","metadata":{"execution":{"iopub.status.busy":"2024-09-13T07:14:17.835008Z","iopub.execute_input":"2024-09-13T07:14:17.835285Z","iopub.status.idle":"2024-09-13T07:14:17.912151Z","shell.execute_reply.started":"2024-09-13T07:14:17.835240Z","shell.execute_reply":"2024-09-13T07:14:17.911490Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"data=data[data['length_eng_sentence']<=20]\ndata=data[data['length_hin_sentence']<=20]","metadata":{"execution":{"iopub.status.busy":"2024-09-13T07:14:17.913384Z","iopub.execute_input":"2024-09-13T07:14:17.913608Z","iopub.status.idle":"2024-09-13T07:14:17.925204Z","shell.execute_reply.started":"2024-09-13T07:14:17.913570Z","shell.execute_reply":"2024-09-13T07:14:17.924403Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-13T07:14:17.926777Z","iopub.execute_input":"2024-09-13T07:14:17.927122Z","iopub.status.idle":"2024-09-13T07:14:17.947581Z","shell.execute_reply.started":"2024-09-13T07:14:17.927043Z","shell.execute_reply":"2024-09-13T07:14:17.946890Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"       source         ...         length_hin_sentence\n82040     ted         ...                          16\n85038     ted         ...                           5\n58018     ted         ...                           8\n74470     ted         ...                           6\n122330    ted         ...                          20\n\n[5 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>source</th>\n      <th>english_sentence</th>\n      <th>hindi_sentence</th>\n      <th>length_eng_sentence</th>\n      <th>length_hin_sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>82040</th>\n      <td>ted</td>\n      <td>we still dont know who her parents are who she is</td>\n      <td>$ हम अभी तक नहीं जानते हैं कि उसके मातापिता कौ...</td>\n      <td>11</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>85038</th>\n      <td>ted</td>\n      <td>no keyboard</td>\n      <td>$ कोई कुंजीपटल नहीं %</td>\n      <td>2</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>58018</th>\n      <td>ted</td>\n      <td>but as far as being a performer</td>\n      <td>$ लेकिन एक कलाकार होने के साथ %</td>\n      <td>7</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>74470</th>\n      <td>ted</td>\n      <td>and this particular balloon</td>\n      <td>$ और यह खास गुब्बारा %</td>\n      <td>4</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>122330</th>\n      <td>ted</td>\n      <td>and its not as hard as you think integrate cli...</td>\n      <td>$ और जितना आपको लगता है यह उतना कठिन नहीं हैअप...</td>\n      <td>16</td>\n      <td>20</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"max_length_src=max(data['length_hin_sentence'])\nmax_length_tar=max(data['length_eng_sentence'])","metadata":{"execution":{"iopub.status.busy":"2024-09-13T07:14:17.948858Z","iopub.execute_input":"2024-09-13T07:14:17.949160Z","iopub.status.idle":"2024-09-13T07:14:17.954986Z","shell.execute_reply.started":"2024-09-13T07:14:17.949105Z","shell.execute_reply":"2024-09-13T07:14:17.954261Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"input_words = sorted(list(eng_word_corpus))\ntarget_words = sorted(list(hindi_word_corpus))\nnum_encoder_tokens = len(eng_word_corpus)\nnum_decoder_tokens = len(hindi_word_corpus)\nnum_encoder_tokens, num_decoder_tokens","metadata":{"execution":{"iopub.status.busy":"2024-09-13T07:14:17.956130Z","iopub.execute_input":"2024-09-13T07:14:17.956410Z","iopub.status.idle":"2024-09-13T07:14:17.981754Z","shell.execute_reply.started":"2024-09-13T07:14:17.956363Z","shell.execute_reply":"2024-09-13T07:14:17.980897Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"(12548, 15514)"},"metadata":{}}]},{"cell_type":"code","source":"num_decoder_tokens+=1","metadata":{"execution":{"iopub.status.busy":"2024-09-13T07:14:17.983222Z","iopub.execute_input":"2024-09-13T07:14:17.983503Z","iopub.status.idle":"2024-09-13T07:14:17.993894Z","shell.execute_reply.started":"2024-09-13T07:14:17.983448Z","shell.execute_reply":"2024-09-13T07:14:17.993114Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"input_token_index = {}\nfor i, word in enumerate(input_words):\n    input_token_index[word] = i + 1\n\ntarget_token_index = {}\nfor i, word in enumerate(target_words):\n    target_token_index[word] = i + 1","metadata":{"execution":{"iopub.status.busy":"2024-09-13T07:14:17.994995Z","iopub.execute_input":"2024-09-13T07:14:17.995567Z","iopub.status.idle":"2024-09-13T07:14:18.014737Z","shell.execute_reply.started":"2024-09-13T07:14:17.995507Z","shell.execute_reply":"2024-09-13T07:14:18.013925Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"reverse_input_char_index = {}\nfor word, i in input_token_index.items():\n    reverse_input_char_index[i] = word\n\nreverse_target_char_index = {}\nfor word, i in target_token_index.items():\n    reverse_target_char_index[i] = word","metadata":{"execution":{"iopub.status.busy":"2024-09-13T07:14:18.015864Z","iopub.execute_input":"2024-09-13T07:14:18.016134Z","iopub.status.idle":"2024-09-13T07:14:18.032272Z","shell.execute_reply.started":"2024-09-13T07:14:18.016083Z","shell.execute_reply":"2024-09-13T07:14:18.031426Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"### Split the data into train and test","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2024-09-13T07:14:18.033705Z","iopub.execute_input":"2024-09-13T07:14:18.034043Z","iopub.status.idle":"2024-09-13T07:14:18.647283Z","shell.execute_reply.started":"2024-09-13T07:14:18.033985Z","shell.execute_reply":"2024-09-13T07:14:18.646123Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"X = data['english_sentence']\ny = data['hindi_sentence']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=42)\nX_train.shape, X_test.shape","metadata":{"execution":{"iopub.status.busy":"2024-09-13T07:14:18.649245Z","iopub.execute_input":"2024-09-13T07:14:18.649556Z","iopub.status.idle":"2024-09-13T07:14:18.667134Z","shell.execute_reply.started":"2024-09-13T07:14:18.649490Z","shell.execute_reply":"2024-09-13T07:14:18.666416Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"((15861,), (3966,))"},"metadata":{}}]},{"cell_type":"markdown","source":"### Let us save this data","metadata":{}},{"cell_type":"code","source":"X_train.to_pickle('X_train.pkl')\nX_test.to_pickle('X_test.pkl')\n","metadata":{"execution":{"iopub.status.busy":"2024-09-13T07:14:18.668737Z","iopub.execute_input":"2024-09-13T07:14:18.669017Z","iopub.status.idle":"2024-09-13T07:14:18.897390Z","shell.execute_reply.started":"2024-09-13T07:14:18.668962Z","shell.execute_reply":"2024-09-13T07:14:18.896592Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"from keras.layers import Input, LSTM, Embedding, Dense\nfrom keras.models import Model","metadata":{"execution":{"iopub.status.busy":"2024-09-13T07:14:18.898926Z","iopub.execute_input":"2024-09-13T07:14:18.899275Z","iopub.status.idle":"2024-09-13T07:14:20.124023Z","shell.execute_reply.started":"2024-09-13T07:14:18.899218Z","shell.execute_reply":"2024-09-13T07:14:20.123063Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"Using TensorFlow backend.\n","output_type":"stream"}]},{"cell_type":"code","source":"def generate_batch(X = X_train, y = y_train, batch_size = 128):\n    ''' Generate a batch of data '''\n    while True:\n        for j in range(0, len(X), batch_size):\n            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n                for t, word in enumerate(input_text.split()):\n                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n                for t, word in enumerate(target_text.split()):\n                    if t<len(target_text.split())-1:\n                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n                    if t>0:\n                        \n                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n            yield([encoder_input_data, decoder_input_data], decoder_target_data)","metadata":{"execution":{"iopub.status.busy":"2024-09-13T07:14:20.125283Z","iopub.execute_input":"2024-09-13T07:14:20.125562Z","iopub.status.idle":"2024-09-13T07:14:20.134125Z","shell.execute_reply.started":"2024-09-13T07:14:20.125511Z","shell.execute_reply":"2024-09-13T07:14:20.133193Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"### Encoder-Decoder Architecture","metadata":{}},{"cell_type":"code","source":"latent_dim=300","metadata":{"execution":{"iopub.status.busy":"2024-09-13T07:14:20.135453Z","iopub.execute_input":"2024-09-13T07:14:20.135755Z","iopub.status.idle":"2024-09-13T07:14:20.148941Z","shell.execute_reply.started":"2024-09-13T07:14:20.135697Z","shell.execute_reply":"2024-09-13T07:14:20.147938Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"encoder_inputs = Input(shape=(None,))\nenc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\nencoder_lstm = LSTM(latent_dim, return_state=True)\nencoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\nencoder_states = [state_h, state_c]","metadata":{"execution":{"iopub.status.busy":"2024-09-13T07:14:20.150238Z","iopub.execute_input":"2024-09-13T07:14:20.150464Z","iopub.status.idle":"2024-09-13T07:14:20.647165Z","shell.execute_reply.started":"2024-09-13T07:14:20.150424Z","shell.execute_reply":"2024-09-13T07:14:20.646481Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\n","output_type":"stream"}]},{"cell_type":"code","source":"decoder_inputs = Input(shape=(None,))\ndec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\ndec_emb = dec_emb_layer(decoder_inputs)\ndecoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\ndecoder_outputs, _, _ = decoder_lstm(dec_emb,\n                                     initial_state=encoder_states)\ndecoder_dense = Dense(num_decoder_tokens, activation='softmax')\ndecoder_outputs = decoder_dense(decoder_outputs)\n\n# Define the model that will turn\n# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\nmodel = Model([encoder_inputs, decoder_inputs], decoder_outputs)","metadata":{"execution":{"iopub.status.busy":"2024-09-13T07:14:20.648634Z","iopub.execute_input":"2024-09-13T07:14:20.648876Z","iopub.status.idle":"2024-09-13T07:14:21.102391Z","shell.execute_reply.started":"2024-09-13T07:14:20.648838Z","shell.execute_reply":"2024-09-13T07:14:21.101415Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"print(model.summary())","metadata":{"execution":{"iopub.status.busy":"2024-09-13T07:14:21.103724Z","iopub.execute_input":"2024-09-13T07:14:21.103975Z","iopub.status.idle":"2024-09-13T07:14:21.110718Z","shell.execute_reply.started":"2024-09-13T07:14:21.103923Z","shell.execute_reply":"2024-09-13T07:14:21.109804Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            (None, None)         0                                            \n__________________________________________________________________________________________________\ninput_2 (InputLayer)            (None, None)         0                                            \n__________________________________________________________________________________________________\nembedding_1 (Embedding)         (None, None, 300)    3764400     input_1[0][0]                    \n__________________________________________________________________________________________________\nembedding_2 (Embedding)         (None, None, 300)    4654500     input_2[0][0]                    \n__________________________________________________________________________________________________\nlstm_1 (LSTM)                   [(None, 300), (None, 721200      embedding_1[0][0]                \n__________________________________________________________________________________________________\nlstm_2 (LSTM)                   [(None, None, 300),  721200      embedding_2[0][0]                \n                                                                 lstm_1[0][1]                     \n                                                                 lstm_1[0][2]                     \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, None, 15515)  4670015     lstm_2[0][0]                     \n==================================================================================================\nTotal params: 14,531,315\nTrainable params: 14,531,315\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\n","output_type":"stream"}]},{"cell_type":"code","source":"model.compile(optimizer='rmsprop', loss='categorical_crossentropy' , metrics = ['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-09-13T07:14:21.111833Z","iopub.execute_input":"2024-09-13T07:14:21.112373Z","iopub.status.idle":"2024-09-13T07:14:21.169380Z","shell.execute_reply.started":"2024-09-13T07:14:21.112037Z","shell.execute_reply":"2024-09-13T07:14:21.168694Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"train_samples = len(X_train)\nval_samples = len(X_test)\nbatch_size = 128\nepochs = 50","metadata":{"execution":{"iopub.status.busy":"2024-09-13T07:14:21.170821Z","iopub.execute_input":"2024-09-13T07:14:21.171126Z","iopub.status.idle":"2024-09-13T07:14:21.175166Z","shell.execute_reply.started":"2024-09-13T07:14:21.171072Z","shell.execute_reply":"2024-09-13T07:14:21.174378Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n                    steps_per_epoch = train_samples//batch_size,\n                    epochs=epochs,\n                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n                    validation_steps = val_samples//batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-09-13T07:14:21.176221Z","iopub.execute_input":"2024-09-13T07:14:21.176447Z","iopub.status.idle":"2024-09-13T08:01:52.828908Z","shell.execute_reply.started":"2024-09-13T07:14:21.176407Z","shell.execute_reply":"2024-09-13T08:01:52.828088Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nWARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nDeprecated in favor of operator or tf.math.divide.\nEpoch 1/50\n123/123 [==============================] - 62s 504ms/step - loss: 6.4792 - acc: 0.1301 - val_loss: 6.2055 - val_acc: 0.1413\nEpoch 2/50\n123/123 [==============================] - 57s 463ms/step - loss: 5.9250 - acc: 0.1527 - val_loss: 5.9176 - val_acc: 0.1688\nEpoch 3/50\n123/123 [==============================] - 57s 463ms/step - loss: 5.5846 - acc: 0.1841 - val_loss: 5.7287 - val_acc: 0.1956\nEpoch 4/50\n123/123 [==============================] - 57s 464ms/step - loss: 5.3360 - acc: 0.2051 - val_loss: 5.6026 - val_acc: 0.2094\nEpoch 5/50\n123/123 [==============================] - 57s 464ms/step - loss: 5.1273 - acc: 0.2217 - val_loss: 5.5381 - val_acc: 0.2206\nEpoch 6/50\n123/123 [==============================] - 57s 462ms/step - loss: 4.9398 - acc: 0.2361 - val_loss: 5.4895 - val_acc: 0.2288\nEpoch 7/50\n123/123 [==============================] - 57s 461ms/step - loss: 4.7696 - acc: 0.2490 - val_loss: 5.4793 - val_acc: 0.2345\nEpoch 8/50\n123/123 [==============================] - 57s 464ms/step - loss: 4.6038 - acc: 0.2619 - val_loss: 5.4505 - val_acc: 0.2392\nEpoch 9/50\n123/123 [==============================] - 57s 462ms/step - loss: 4.4476 - acc: 0.2730 - val_loss: 5.4204 - val_acc: 0.2411\nEpoch 10/50\n123/123 [==============================] - 57s 463ms/step - loss: 4.2986 - acc: 0.2840 - val_loss: 5.4105 - val_acc: 0.2484\nEpoch 11/50\n123/123 [==============================] - 57s 463ms/step - loss: 4.1544 - acc: 0.2959 - val_loss: 5.4055 - val_acc: 0.2463\nEpoch 12/50\n123/123 [==============================] - 57s 462ms/step - loss: 4.0149 - acc: 0.3087 - val_loss: 5.4043 - val_acc: 0.2484\nEpoch 13/50\n123/123 [==============================] - 57s 463ms/step - loss: 3.8791 - acc: 0.3204 - val_loss: 5.4059 - val_acc: 0.2499\nEpoch 14/50\n123/123 [==============================] - 57s 462ms/step - loss: 3.7409 - acc: 0.3346 - val_loss: 5.4392 - val_acc: 0.2483\nEpoch 15/50\n123/123 [==============================] - 57s 463ms/step - loss: 3.6085 - acc: 0.3492 - val_loss: 5.4456 - val_acc: 0.2480\nEpoch 16/50\n123/123 [==============================] - 57s 463ms/step - loss: 3.4769 - acc: 0.3629 - val_loss: 5.4478 - val_acc: 0.2499\nEpoch 17/50\n123/123 [==============================] - 57s 460ms/step - loss: 3.3472 - acc: 0.3788 - val_loss: 5.4771 - val_acc: 0.2466\nEpoch 18/50\n123/123 [==============================] - 57s 462ms/step - loss: 3.2198 - acc: 0.3953 - val_loss: 5.4923 - val_acc: 0.2474\nEpoch 19/50\n123/123 [==============================] - 57s 463ms/step - loss: 3.0941 - acc: 0.4121 - val_loss: 5.5122 - val_acc: 0.2477\nEpoch 20/50\n123/123 [==============================] - 57s 464ms/step - loss: 2.9732 - acc: 0.4292 - val_loss: 5.5493 - val_acc: 0.2448\nEpoch 21/50\n123/123 [==============================] - 57s 463ms/step - loss: 2.8526 - acc: 0.4491 - val_loss: 5.5875 - val_acc: 0.2439\nEpoch 22/50\n123/123 [==============================] - 57s 463ms/step - loss: 2.7332 - acc: 0.4680 - val_loss: 5.6230 - val_acc: 0.2429\nEpoch 23/50\n123/123 [==============================] - 57s 464ms/step - loss: 2.6150 - acc: 0.4879 - val_loss: 5.6814 - val_acc: 0.2455\nEpoch 24/50\n123/123 [==============================] - 57s 462ms/step - loss: 2.4979 - acc: 0.5102 - val_loss: 5.7227 - val_acc: 0.2425\nEpoch 25/50\n123/123 [==============================] - 57s 462ms/step - loss: 2.3881 - acc: 0.5295 - val_loss: 5.7602 - val_acc: 0.2368\nEpoch 26/50\n123/123 [==============================] - 57s 464ms/step - loss: 2.2771 - acc: 0.5520 - val_loss: 5.8019 - val_acc: 0.2349\nEpoch 27/50\n123/123 [==============================] - 57s 464ms/step - loss: 2.1691 - acc: 0.5729 - val_loss: 5.8240 - val_acc: 0.2391\nEpoch 28/50\n123/123 [==============================] - 57s 463ms/step - loss: 2.0624 - acc: 0.5947 - val_loss: 5.8970 - val_acc: 0.2310\nEpoch 29/50\n123/123 [==============================] - 57s 463ms/step - loss: 1.9643 - acc: 0.6155 - val_loss: 5.9174 - val_acc: 0.2356\nEpoch 30/50\n123/123 [==============================] - 57s 465ms/step - loss: 1.8627 - acc: 0.6371 - val_loss: 5.9689 - val_acc: 0.2307\nEpoch 31/50\n123/123 [==============================] - 57s 464ms/step - loss: 1.7666 - acc: 0.6585 - val_loss: 6.0432 - val_acc: 0.2285\nEpoch 32/50\n123/123 [==============================] - 57s 466ms/step - loss: 1.6752 - acc: 0.6779 - val_loss: 6.0772 - val_acc: 0.2291\nEpoch 33/50\n123/123 [==============================] - 57s 463ms/step - loss: 1.5877 - acc: 0.6969 - val_loss: 6.1267 - val_acc: 0.2263\nEpoch 34/50\n123/123 [==============================] - 57s 461ms/step - loss: 1.4981 - acc: 0.7162 - val_loss: 6.1624 - val_acc: 0.2243\nEpoch 35/50\n123/123 [==============================] - 57s 462ms/step - loss: 1.4140 - acc: 0.7356 - val_loss: 6.2279 - val_acc: 0.2211\nEpoch 36/50\n123/123 [==============================] - 57s 460ms/step - loss: 1.3361 - acc: 0.7516 - val_loss: 6.2627 - val_acc: 0.2220\nEpoch 37/50\n123/123 [==============================] - 57s 465ms/step - loss: 1.2585 - acc: 0.7701 - val_loss: 6.3154 - val_acc: 0.2245\nEpoch 38/50\n123/123 [==============================] - 57s 462ms/step - loss: 1.1846 - acc: 0.7867 - val_loss: 6.3583 - val_acc: 0.2236\nEpoch 39/50\n123/123 [==============================] - 57s 462ms/step - loss: 1.1145 - acc: 0.8028 - val_loss: 6.4209 - val_acc: 0.2200\nEpoch 40/50\n123/123 [==============================] - 57s 462ms/step - loss: 1.0474 - acc: 0.8177 - val_loss: 6.4587 - val_acc: 0.2182\nEpoch 41/50\n123/123 [==============================] - 57s 460ms/step - loss: 0.9835 - acc: 0.8312 - val_loss: 6.4904 - val_acc: 0.2201\nEpoch 42/50\n123/123 [==============================] - 57s 461ms/step - loss: 0.9209 - acc: 0.8457 - val_loss: 6.5280 - val_acc: 0.2188\nEpoch 43/50\n123/123 [==============================] - 57s 462ms/step - loss: 0.8650 - acc: 0.8584 - val_loss: 6.5850 - val_acc: 0.2169\nEpoch 44/50\n123/123 [==============================] - 57s 461ms/step - loss: 0.8094 - acc: 0.8701 - val_loss: 6.6205 - val_acc: 0.2173\nEpoch 45/50\n123/123 [==============================] - 57s 462ms/step - loss: 0.7550 - acc: 0.8825 - val_loss: 6.6623 - val_acc: 0.2175\nEpoch 46/50\n123/123 [==============================] - 57s 462ms/step - loss: 0.7024 - acc: 0.8930 - val_loss: 6.7178 - val_acc: 0.2150\nEpoch 47/50\n123/123 [==============================] - 57s 461ms/step - loss: 0.6580 - acc: 0.9021 - val_loss: 6.7454 - val_acc: 0.2152\nEpoch 48/50\n123/123 [==============================] - 57s 463ms/step - loss: 0.6115 - acc: 0.9122 - val_loss: 6.7723 - val_acc: 0.2146\nEpoch 49/50\n123/123 [==============================] - 57s 461ms/step - loss: 0.5709 - acc: 0.9207 - val_loss: 6.8125 - val_acc: 0.2158\nEpoch 50/50\n123/123 [==============================] - 57s 461ms/step - loss: 0.5325 - acc: 0.9278 - val_loss: 6.8796 - val_acc: 0.2168\n","output_type":"stream"},{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7d9a23d168d0>"},"metadata":{}}]},{"cell_type":"code","source":"model.save_weights('nmt_weights.h5')","metadata":{"execution":{"iopub.status.busy":"2024-09-13T08:01:52.831829Z","iopub.execute_input":"2024-09-13T08:01:52.832183Z","iopub.status.idle":"2024-09-13T08:01:53.072945Z","shell.execute_reply.started":"2024-09-13T08:01:52.832133Z","shell.execute_reply":"2024-09-13T08:01:53.071907Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"encoder_model = Model(encoder_inputs, encoder_states)\n\n# Decoder setup\n# Below tensors will hold the states of the previous time step\ndecoder_state_input_h = Input(shape=(latent_dim,))\ndecoder_state_input_c = Input(shape=(latent_dim,))\ndecoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n\ndec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n\n# To predict the next word in the sequence, set the initial states to the states from the previous time step\ndecoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\ndecoder_states2 = [state_h2, state_c2]\ndecoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n\n# Final decoder model\ndecoder_model = Model(\n    [decoder_inputs] + decoder_states_inputs,\n    [decoder_outputs2] + decoder_states2)","metadata":{"execution":{"iopub.status.busy":"2024-09-13T08:01:53.074466Z","iopub.execute_input":"2024-09-13T08:01:53.074793Z","iopub.status.idle":"2024-09-13T08:01:53.275741Z","shell.execute_reply.started":"2024-09-13T08:01:53.074738Z","shell.execute_reply":"2024-09-13T08:01:53.274828Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"def decode_sequence(input_seq):\n    # Encode the input as state vectors.\n    states_value = encoder_model.predict(input_seq)\n    # Generate empty target sequence of length 1.\n    target_seq = np.zeros((1,1))\n    # Populate the first character of target sequence with the start character.\n    target_seq[0, 0] = target_token_index['$']\n\n    # Sampling loop for a batch of sequences\n    # (to simplify, here we assume a batch of size 1).\n    stop_condition = False\n    decoded_sentence = ''\n    while not stop_condition:\n        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n\n        # Sample a token\n        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n        sampled_char = reverse_target_char_index[sampled_token_index]\n        decoded_sentence += ' '+sampled_char\n\n        # Exit condition: either hit max length\n        if (sampled_char == '%' or\n           len(decoded_sentence) > 50):\n            stop_condition = True\n\n        # Update the target sequence (of length 1).\n        target_seq = np.zeros((1,1))\n        target_seq[0, 0] = sampled_token_index\n\n        # Update states\n        states_value = [h, c]\n\n    return decoded_sentence","metadata":{"execution":{"iopub.status.busy":"2024-09-13T08:01:53.277022Z","iopub.execute_input":"2024-09-13T08:01:53.277309Z","iopub.status.idle":"2024-09-13T08:01:53.285033Z","shell.execute_reply.started":"2024-09-13T08:01:53.277245Z","shell.execute_reply":"2024-09-13T08:01:53.284083Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"train_gen = generate_batch(X_train, y_train, batch_size = 1)\nk=-1","metadata":{"execution":{"iopub.status.busy":"2024-09-13T08:01:53.286417Z","iopub.execute_input":"2024-09-13T08:01:53.286754Z","iopub.status.idle":"2024-09-13T08:01:53.299043Z","shell.execute_reply.started":"2024-09-13T08:01:53.286692Z","shell.execute_reply":"2024-09-13T08:01:53.298382Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"k+=1\n(input_seq, actual_output), _ = next(train_gen)\ndecoded_sentence = decode_sequence(input_seq)\nprint('Input English sentence:', X_train[k:k+1].values[0])\nprint('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\nprint('Predicted Hindi Translation:', decoded_sentence[:-4])","metadata":{"execution":{"iopub.status.busy":"2024-09-13T08:01:53.300548Z","iopub.execute_input":"2024-09-13T08:01:53.300862Z","iopub.status.idle":"2024-09-13T08:01:53.667212Z","shell.execute_reply.started":"2024-09-13T08:01:53.300805Z","shell.execute_reply":"2024-09-13T08:01:53.666094Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"Input English sentence: of a whole bunch of little particles\nActual Hindi Translation: ोटी चीजों से बना \nPredicted Hindi Translation:  कम से कि लोग सर \n","output_type":"stream"}]},{"cell_type":"code","source":"k+=1\n(input_seq, actual_output), _ = next(train_gen)\ndecoded_sentence = decode_sequence(input_seq)\nprint('Input English sentence:', X_train[k:k+1].values[0])\nprint('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\nprint('Predicted Hindi Translation:', decoded_sentence[:-4])","metadata":{"execution":{"iopub.status.busy":"2024-09-13T08:10:27.168655Z","iopub.execute_input":"2024-09-13T08:10:27.168971Z","iopub.status.idle":"2024-09-13T08:10:27.207190Z","shell.execute_reply.started":"2024-09-13T08:10:27.168926Z","shell.execute_reply":"2024-09-13T08:10:27.206239Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"Input English sentence: no one was a hero no one was a hero\nActual Hindi Translation: भी नायक नहीं था कोई भी नायक नहीं \nPredicted Hindi Translation:  कोई भी नायक नहीं था कोई भी कोई ज़रुरत नहीं \n","output_type":"stream"}]},{"cell_type":"code","source":"k+=1\n(input_seq, actual_output), _ = next(train_gen)\ndecoded_sentence = decode_sequence(input_seq)\nprint('Input English sentence:', X_train[k:k+1].values[0])\nprint('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\nprint('Predicted Hindi Translation:', decoded_sentence[:-4])","metadata":{"execution":{"iopub.status.busy":"2024-09-13T08:10:46.836116Z","iopub.execute_input":"2024-09-13T08:10:46.836432Z","iopub.status.idle":"2024-09-13T08:10:46.865867Z","shell.execute_reply.started":"2024-09-13T08:10:46.836386Z","shell.execute_reply":"2024-09-13T08:10:46.865120Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"Input English sentence: and about three years ago\nActual Hindi Translation: गभग तीन साल पह\nPredicted Hindi Translation:  और लगभग तीन साल पह\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}